Final Project: Statistical Analysis on Absenteeism at work Datasethttp://archive.ics.uci.edu/ml/datasets/Absenteeism+at+workExecutive summaryEmployee absenteeism can result in substantial productivity losses as well as financial losses. It also creates additional work for employees that show up, resulting in dissatisfaction and low engagement. Absenteeism is a prevalent problem, with chronic health issues alone accounting for $84 billion in annual productivity losses in the United States. Other factors, such as mental health issues, work-related stress, poor working conditions, family-related issues, and workplace injuries, can all contribute to employee absenteeism, resulting in significant decreases in productivity and financial costs for businesses. To better understand and address this issue, I ran an analysis on a database of absence records from a Brazilian courier company. The dataset includes 21 absence explanation categories as well as other variables such as transportation costs, distance from work to home, and disciplinary failure.According to my findings, the target variable of absenteeism time is not normallyÊdistributed, with most employeesÊabsent less than 10 hours each time. Furthermore, with the exception of reason 19, there were no correlations higher than 20% between allÊfactors and absentee time. From the descriptive analysis, I identified that musculoskeletal problems, injuries/poisoning, and medical consultations resulted in the longest total hours of absence, which makes sense given that these types of diseases take longer to heal. Dental consultations, physiotherapy, and medical consultations were the most frequently reported reasons for absenteeism.Due to data limitations such as imbalanced binary and categorical variables, normality violations, and low statistical measures that prevented the implementation of a linear regression model. I ultimately chose cluster analysis as my final statistical model. Using this technique of analysis, I was able to identify groups of employees who shared similar features, such as service time, BMI and age, and other aspects. The information gained from cluster analysis could assist a company to develop new policies for employees or allocate them to certain teams, which can help reduce absenteeism.Overall, the analysis gives significant insights into the complicated topic of absenteeism and enables companies to make informed hiring and scheduling decisions in order to avoid productivity losses and expenses related to absenteeism.Table of ContentsProblem significance Data source/preparation HypothesisDescriptive StatisticsStatistical Models and their robustness checksActionable insights based on the resultsLimitations of the analysisProblem significanceEmployers face a serious problem with employee absenteeism because it reduces productivity, costs money, and lowers employee morale. While health issues account for a sizable amount of absenteeism expenses, other variables might cause lost productivity and higher expenditures for businesses. Companies can establish strategies to reduce the risk of employee absence by examining absenteeism data in order to better understand the factors that contribute to absenteeism. This could result in increased output, financial savings, and a healthier workplace.Data source/preparationI obtained the dataset from the UCI Machine Learning Repository, which contains records of absenteeism at work at a courier firm in Brazil from July 2007 to July 2010. The dataset contains 21 variables, including the response variable Absenteeism_time_in_hours and other employee-specific information such as number of pets, distance to work, ages, IMB, AbsenceReason, AbsenceMonth, WeekDay, Seasons, TranspExpense, Service time, WorkAVGday, HitTarget, Disciplinary failure, Education, Son (number of kids), SocialDrinker, SocialSmoker, Weight, and Height. The dataset has no missing values.Since the numerical variable,ÊWork_load_Average/day (WorkAVGday) has six digits and is significantly greater than other numerical values, I converted it into a log variable to prevent heteroscedasticity. The dataset contains a variety of categorical variables, including binary (e.g., SocialDrinker, SocialSmoker) and ordinal (e.g., season, day of the week, education). I also converted the values of a categorical variable from 'Yes' and 'No' to '1' and '0' to make it compliant with the SAS program.HypothesisSeveral assumptions were made regarding the relationship between various variables and absence in light of the employee absenteeism dataset. First, it was thought that the absent reason variable might be the factor that influences absence the most. This might be the case because some absence-related factors, such asÊillness or emergency situations, may be more likely to result in extended absences. Additionally, it was thought that the number of hours worked each day would positively correlate with the amount of absenteeism because workers who put in more time at the office could be more susceptible to getting sick or tired. Another supposition was that, maybe as a result of long commutes or transportation challenges, the distance between an employee's place of residence and place of employment would be positively associated with absenteeism. Finally, it was hypothesized that having a chronic illness would have a favorable impact on absenteeism since people with chronic illnesses may need to see a doctor more frequently or have health problems more frequently. These presumptions can act as a foundation for future research into absenteeism trends and could direct the creation of plans for lowering absence in the workplace.Descriptive StatisticsBelow is the dataset head with 10 rows:When I initially began analyzing this dataset, the category variable Absence Reason captured my interest because it contains 28 various types of reasons linked to medical conditions. I got to the conclusion that it was critical to explore this variable in greater depth in order to gain relevant insights for developing a hypothesis. Graph 1The first graph's data shows that among the 28 different categorical variables that make up the Absence Reason variable, medical consultation (Reason 23), dental consultation (Reason 28), and physiotherapy (Reason 27) are the three most frequently reported causes of absenteeism. Moving on to the second graph, it can be noted that the top three causes of the greatest number of total absence hours among the dataset's employees are musculoskeletal diseaseÊ(Reason 13), injuries or poisoning (Reason 19), and medical consultations (Reason 23)Graph 2In graph 3, the employees' educational background is indicated by bars for each cause for absence, with the y-axis denoting the absence time and the x-axis the reason for the absence. The findings show that the majority of employees who reported absenteeism held a high school diploma for the majority of causes. However, for the reason of Certain Infectious and Parasitic Diseases, the employees who reported absenteeism had an equal distribution of postgraduate and high school degrees.The pie chart in graph 4 demonstrates that 83% of the dataset's employees had only completed high school, while 17% had a graduate or postgraduate degree. As a result, the dataset's population is dominated by those with a high school diploma. Therefore, the high school degree holders represent the majority of the population in the dataset. As a result, the bar graph in graph 3 shows that most of the absent employees also held a high school degree. From this analysis, it can be inferred that the education degree variable does not capture a diverse sample of the population.Graph 3Graph 4The graphs 5 and 6 illustrate the total number of hours worked and the frequency of absences by day of the week. Graph 5 illustrates that Tuesday has the largest rate of absence, accounting for nearly 30% of all absences, as well as the longest duration of absence on this day. Friday, on the other hand, has the shortest time of absence, which is unsurprising given that it is the last working day of the week. When we look at graph 6, we can see that the frequency of absence is equivalent, accounting for little more than 20% on Tuesday, Wednesday, and Thursday, with the lowest frequency of absence occurring on Friday. This implies that, while Tuesday has the greatest duration of absence, more absences stillÊoccur on other weekdays, proving that other factors besides the day of the week may be at work.Graph 5Graph 6Regarding the variable of Absence Month in relation to total hours and absence frequency,Êbar chart 7 shows that March and July have the highest total hours of absence among employees. However, if we look at the absence frequency shown in graph 8, we can see that March continues to have the greatest frequency, while the other months have a reasonably equal frequency ranging from 6% to 8%.Graph 7                                                                       Graph 8                                                                      Graph 9 demonstrates the Absenteeism time distribution which is the response variable, and it is clearly not normally distributed and is also skewed to the right.  We can see from this that the majority of people are absent for less than 10 hours each time.Graph 9Graph 10Following a thorough examination of the relationship between AbsentTime and all other variables using Pearson Correlation Coefficients, it was revealed that no correlations exceeded 20%. However, Reason19, which is classed as Injury, poisoning, and some other outcomes of external sources, exhibited a statistically significant positive correlation of 20.2%. This finding implies that the occurrence of Reason19 and the duration of AbsentTime have a moderate but relevant association. More research may be required to investigate any underlying elements that contribute to this association.Furthermore, at the 0.05 significant level, other factors such as Reason 9 (19%), Reason 12 (13%), and Reason 13 (18%) revealed an association. It indicates that the relationship between causes is stronger than the relationship between other factors.Additionally, when we examine the continuous variables, we can see that DistWork (negative 9%), DiscipFailure (negative 12%), Son (positive 11%), and Hight (positive 14%) are significantly associated. These findings imply that characteristics such as commute time to work, disciplinary concerns, number of children, and height may all play a role in influencing AbsentTime. More research is needed to investigate the nature and degree of these correlations, as well as any underlying factors that may contribute to these interactions.Statistical Models and their robustness checksOne-way ANOVA testThe one-wayÊANOVA test is commonly used to see if there are any significant differences in the means of three or more groups based on a continuous variable. A t-test may be more suited if we have two variables and wish to see if there are any significant variations in their means. A one-wayÊANOVA test would be suitable if we have different groups or levels for one of the variables and want to determine whether there are significant variations in their means while adjusting for the other variable. In this particular instance of the above data, where the variable AbsenceReason has 28 levels, the one-wayÊANOVA test is an appropriate method to determine whether there are significant variations in the mean AbsentTime across these groups.The one-way ANOVA test was used to see if there were any significant variations in average AbsentTime across the 28 AbsenceReason levels. The model is statistically significant, with a F value of 7.15 and a p-value of.0001, indicating that at least one of the AbsenceReason levels has a significantly different average AbsentTime than the others. The R-squared value of 0.2133 suggests that changes in AbsenceReason levels explain 21.33% of the overall variance in AbsentTime. The overall mean AbsentTime was 6.92, with a coefficient of variation of 173.97 and a root mean square error of 12.05.The ANOVA table also demonstrates that the AbsenceReason factor has a significant effect on AbsentTime, with a mean square of 1037.66 and a p-value of.0001. Based on these findings, the null hypothesis, which claims that there are no significant changes in AbsentTime across the 28 levels of AbsenceReason, can be rejected.Class Level InformationClassLevelsValuesAbsenceReason280 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28Number of Observations Read741Number of Observations Used740Dependent Variable: AbsentTime AbsentTimeSourceDFSum of SquaresMean SquareF ValuePrÊ>ÊFModel2728016.76561037.65807.15<.0001Error712103314.9965145.1053ÊÊCorrected Total739131331.7622ÊÊÊR-SquareCoeff VarRoot MSEAbsentTimeÊMean0.213328173.966012.045976.924324SourceDFAnova SSMean SquareF ValuePrÊ>ÊFAbsenceReason2728016.765631037.657997.15<.0001Tukey's Studentized Range (HSD) Test for AbsentTimeNote:This test controls the Type I experimentwise error rate, but it generally has a higher Type II error rate than REGWQ.Alpha0.05Error Degrees of Freedom712Error Mean Square145.1053Critical Value of Studentized Range5.27483Minimum Significant Difference30.204Harmonic Mean of Cell Sizes4.425716Based on the Tukey lines, there is no statistically significant difference between absent reasons 9, 2, 12, 6, 19, and 13, but these reasons are significantly different from the other reasons for absence.Linear RegressionThe linear regression analysis was performed with AbsentTime as the dependent variable and all other variables as independent variables.The p-value of less than 0.05 indicates that the model is significant, meaning that at least one of the predictors has a statistically significant effect on the response variable. The R-squared value of 0.25 indicates that 25% of the variability in the response variable is explained by the model. According to the vif values, all factors showed less than 5 indicating that multicollinearity is not a concern for the modelBased on the p-values, the variables Distance to Work and Absent Reasons 1, 6, 7, 9, 10, 13, 18, and 19 have p-values less than the alpha value. Therefore, it can be concluded that there is a statistically significant relationship between these predictor variables and the response variable. Moreover, it is suggested to keep only these variables in the model.For further analysis, there was implemented stepwise and backward selection models. However, the R square for those models yielded too low to include them for further analysis.The residual plot for the linear regression model used for analyzing absenteeism indicates that there is probably aÊnormality or homoscedasticity violations, as indicated by the residual plot..Two-way Chi-square testAt a significance threshold of 0.05, the chi-square test finds no significant relationship between the AbsenceReason and WeekDay variables. However, because 63% of the cells had predicted counts less than 5, there may be a problem with the test's validity.The likelihood ratio chi-square test and the Mantel-Haenszel chi-square test both revealed no significant relationship between the variables. The Phi Coefficient and Contingency Coefficient both show a moderate relationship between the variables, however Cramer's V shows a poor relationship. Because they evaluate distinct features of the relationship between the variables, these measures of association do not necessarily contradict the lack of significance in the chi-square tests.Overall, the conclusion is that there may be a moderate relationship between AbsenceReason and WeekDay, but the significance of this relationship is unknown due to potential concerns with the chi-square test's validity.Statistics for Table of AbsenceReason by WeekDayStatisticDFValueProbWARNING: 63% of the cells have expected counts lessthan 5. Chi-Square may not be a valid test.Chi-Square108132.01700.0581Likelihood Ratio Chi-Square108138.86250.0243Mantel-Haenszel Chi-Square19.99880.0016Phi CoefficientÊ0.4224ÊContingency CoefficientÊ0.3891ÊCramer's VÊ0.2112ÊPrincipal Component AnalysisNon-parametric models cannot be used because our response variable is continuous. As a result, I chose principal component analysis to overcome the dimensionality concerns and discover the underlying components that can be used to conduct a cluster analysis. By merging correlated variables, we can minimize the number of variables and generate a smaller collection of independent components or factors that can account for the bulk of the variance in the original data. I can find unique groups of similar observations and acquire a greater understanding of the patterns present in our data by using these parameters as input for our cluster analysis.According to this PCA analysis, five factors should be retained. These five factors explain a cumulative proportion of 0.763 of the total variances in the data.Based on the analysis of the eigenvectors and factor patterns, the variables Hight, WorkAVGDay, and HitTarget were found to have a low contribution to the factor weight. Therefore, these variables were eliminated from the analysis.Adjusted Principal Component AnalysisThe variables Hight, WorkAVGDay, and HitTarget have been determined to have little contribution to the component weight based on an analysis of the eigenvectors and factor patterns in the original PCA. As a result, these factors were removed from the analysis. According to this PCA analysis, three factors should be retained. These three factors explain a cumulative proportion of 0.733 of the total variances in the data. Factor 1 explains 28.42% of the overall variance, while Factor 2 explains 16% of the variance.According to the results of the factor pattern correlation analysis and eigenvector table, we can infer that the first factor consist of the variables ServiceTime, Age, Weight, and BMI, while the second factor consist of the variables DistWork and TranspExpense.K-Mean Clustering Analysis on PCA FactorsThe k-means clustering analysis grouped the observations into three clusters based on the values of two principal components (Prin1, Prin2)The overall R-squared value indicates that the three principal components explain 48.44% of the total variance in the data. The pseudo-F statistic of 346.23 suggests that the clusters are significantly different from each other.According to the cubic clustering criteria of -11.862, three clusters may not be the ideal number of clusters. However, the warning notice suggests that the findings for correlated variables may be erroneous. Overall, the research reveals that the clustering factors are not significantly connectedÊand that three groups may not be the ideal number of clusters. Further investigation may be required to establish the validity of the clustering results and gain insights from them.The graph shows that the majority of the data records belong to two distinct clusters, red and blue, with aÊsmall proportion of records belonging to the green cluster.Actionable Insights Based on the ResultsAccording to the findings, there are three main employee profiles. This data can be used by the organization to identify the features of each employee profile and modify HR policies and procedures accordingly. For example, the employer may discover that one group is more likely to take time off during a specific season, while another group may take time off based on other key health condition variables. Moreover,Êaccording to the findingÊseveral characteristics, such as ServiceTime, Age, Weight, and BMI, have a significant impact on employee absenteeism. This information can be used by the organization to change its recruitment strategy and hire people who are more likely to work productively with low absenteeism.Limitations of the analysisIt is critical to recognize that the analysis offered has limitations. In particular, the dataset may not be representative of the genuine population and may be biased. Descriptive analysis found that the majority of employees only had a high school diploma, implying that the dataset may only reflect a certain division with an education requirement limited to high school diplomas. Furthermore, the statistical measures of the linear regression model were quite poor, and assumptions were partially broken. Moving forward, it may be preferable to use supervised and unsupervised machine learning techniques, such as decision trees and neural networks, with an 80/20 training and testing split ratio. Given the imbalanced nature of the category variables and the target variable's considerable right skew, these algorithms may be more appropriate for analysis.